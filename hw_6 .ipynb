{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torch import nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jan  5 12:21:35 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 410.73       Driver Version: 410.73       CUDA Version: 10.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 108...  Off  | 00000000:02:00.0 Off |                  N/A |\n",
      "| 29%   36C    P8    15W / 250W |  10532MiB / 11178MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce GTX 108...  Off  | 00000000:03:00.0 Off |                  N/A |\n",
      "| 57%   75C    P2   177W / 250W |   7581MiB / 11178MiB |     86%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce GTX 108...  Off  | 00000000:82:00.0 Off |                  N/A |\n",
      "| 71%   83C    P2   232W / 250W |  10803MiB / 11178MiB |     94%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  GeForce GTX 108...  Off  | 00000000:83:00.0 Off |                  N/A |\n",
      "| 62%   80C    P2   195W / 250W |  10088MiB / 11178MiB |     96%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0      5417      C   /opt/conda/envs/pt-stable/bin/python        4887MiB |\n",
      "|    1     41415      C   /opt/conda/envs/pt-stable/bin/python        2969MiB |\n",
      "|    3     23215      C   /opt/conda/bin/python3.7                    5249MiB |\n",
      "|    3     24503      C   /opt/conda/bin/python3.7                    2433MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi # check GPU status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch reads this environment variable\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\" # options: 0, 1, 2, 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root ={\n",
    "    \"train\":\"train\",\n",
    "    \"valid\":\"valid\",\n",
    "    \"test\":\"test\"    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.utils.data.dataset.Dataset"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.utils.data.Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ImageFolder(data_root[\"train\"],\n",
    "                           transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader= DataLoader(train_dataset, batch_size=64,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=iter(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y=next(iter(train_dataloader)) #Iterator读取了第一批64个数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 8, 1, 6, 4, 8, 7, 0, 0, 6, 4, 3, 1, 2, 5, 1, 4, 2, 1, 3, 2, 5, 1, 5,\n",
       "        1, 4, 5, 4, 1, 4, 0, 5, 1, 3, 0, 2, 7, 7, 9, 4, 0, 9, 4, 9, 0, 7, 1, 7,\n",
       "        5, 2, 7, 4, 9, 5, 9, 4, 0, 0, 3, 4, 0, 9, 2, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = torchvision.models.vgg11(pretrained=True)\n",
    "model = torch.load(\"\\mynet.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.classifier = nn.Sequential(\n",
    "nn.Linear(in_features=25088, out_features=512, bias=True),\n",
    "nn.ReLU(inplace=True),\n",
    "nn.Dropout(p=0.5, inplace=False),\n",
    "nn.Linear(in_features=512, out_features=512, bias=True),\n",
    "nn.ReLU(inplace=True),\n",
    "nn.Dropout(p=0.5, inplace=False),\n",
    "\n",
    "nn.Linear(in_features=512, out_features=10, bias=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=25088, out_features=512, bias=True)\n",
       "  (1): ReLU(inplace=True)\n",
       "  (2): Dropout(p=0.5, inplace=False)\n",
       "  (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (4): ReLU(inplace=True)\n",
       "  (5): Dropout(p=0.5, inplace=False)\n",
       "  (6): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y_pred = model(X)\n",
    "# acc =float(torch.sum(torch.argmax(Y_pred, 1) ==Y )) / float(len(Y))\n",
    "# acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.SGD(model.parameters(),1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss(model(X),Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------epoch 1--------\n",
      "Iter 200:loss 0.957959 accuarcy 0.7031\n",
      "Iter 400:loss 0.814629 accuarcy 0.7344\n",
      "Iter 600:loss 0.755053 accuarcy 0.7031\n",
      "Iter 800:loss 0.552171 accuarcy 0.7812\n",
      "Iter 1000:loss 0.654004 accuarcy 0.7500\n",
      "Iter 1200:loss 0.896904 accuarcy 0.7344\n",
      "Iter 1400:loss 0.446449 accuarcy 0.8281\n",
      "--------epoch 2--------\n",
      "Iter 200:loss 0.740757 accuarcy 0.7500\n",
      "Iter 400:loss 0.518233 accuarcy 0.8125\n",
      "Iter 600:loss 0.520742 accuarcy 0.7969\n",
      "Iter 800:loss 0.369287 accuarcy 0.9219\n",
      "Iter 1000:loss 0.593037 accuarcy 0.7188\n",
      "Iter 1200:loss 0.392950 accuarcy 0.8594\n",
      "Iter 1400:loss 0.501656 accuarcy 0.8281\n",
      "--------epoch 3--------\n",
      "Iter 200:loss 0.411496 accuarcy 0.8594\n",
      "Iter 400:loss 0.346921 accuarcy 0.9062\n",
      "Iter 600:loss 0.806195 accuarcy 0.6875\n",
      "Iter 800:loss 0.588158 accuarcy 0.7969\n",
      "Iter 1000:loss 0.711640 accuarcy 0.7656\n",
      "Iter 1200:loss 0.353300 accuarcy 0.8750\n",
      "Iter 1400:loss 0.525600 accuarcy 0.8281\n",
      "--------epoch 4--------\n",
      "Iter 200:loss 0.542823 accuarcy 0.8281\n",
      "Iter 400:loss 0.386795 accuarcy 0.8438\n",
      "Iter 600:loss 0.459578 accuarcy 0.8750\n",
      "Iter 800:loss 0.312438 accuarcy 0.8594\n",
      "Iter 1000:loss 0.389000 accuarcy 0.8906\n",
      "Iter 1200:loss 0.343526 accuarcy 0.9062\n",
      "Iter 1400:loss 0.424286 accuarcy 0.8594\n",
      "--------epoch 5--------\n",
      "Iter 200:loss 0.327652 accuarcy 0.8594\n",
      "Iter 400:loss 0.323788 accuarcy 0.8750\n",
      "Iter 600:loss 0.479239 accuarcy 0.8438\n",
      "Iter 800:loss 0.555744 accuarcy 0.7812\n",
      "Iter 1000:loss 0.280456 accuarcy 0.9219\n",
      "Iter 1200:loss 0.430654 accuarcy 0.8594\n",
      "Iter 1400:loss 0.386529 accuarcy 0.8594\n",
      "--------epoch 6--------\n",
      "Iter 200:loss 0.312598 accuarcy 0.8750\n",
      "Iter 400:loss 0.581465 accuarcy 0.7812\n",
      "Iter 600:loss 0.469787 accuarcy 0.8281\n",
      "Iter 800:loss 0.515224 accuarcy 0.8281\n",
      "Iter 1000:loss 0.596707 accuarcy 0.8125\n",
      "Iter 1200:loss 0.463765 accuarcy 0.8594\n",
      "Iter 1400:loss 0.377354 accuarcy 0.8750\n",
      "--------epoch 7--------\n",
      "Iter 200:loss 0.246999 accuarcy 0.9062\n",
      "Iter 400:loss 0.371321 accuarcy 0.8906\n",
      "Iter 600:loss 0.347600 accuarcy 0.8750\n",
      "Iter 800:loss 0.431962 accuarcy 0.8750\n",
      "Iter 1000:loss 0.339979 accuarcy 0.9219\n",
      "Iter 1200:loss 0.242480 accuarcy 0.9219\n",
      "Iter 1400:loss 0.448471 accuarcy 0.8281\n",
      "--------epoch 8--------\n",
      "Iter 200:loss 0.489979 accuarcy 0.7969\n",
      "Iter 400:loss 0.339768 accuarcy 0.8906\n",
      "Iter 600:loss 0.323982 accuarcy 0.8906\n",
      "Iter 800:loss 0.252675 accuarcy 0.8906\n",
      "Iter 1000:loss 0.228427 accuarcy 0.8906\n",
      "Iter 1200:loss 0.328328 accuarcy 0.9062\n",
      "Iter 1400:loss 0.512722 accuarcy 0.8750\n",
      "--------epoch 9--------\n",
      "Iter 200:loss 0.456356 accuarcy 0.8594\n",
      "Iter 400:loss 0.375623 accuarcy 0.8750\n",
      "Iter 600:loss 0.180051 accuarcy 0.9219\n",
      "Iter 800:loss 0.412941 accuarcy 0.8906\n",
      "Iter 1000:loss 0.263510 accuarcy 0.9375\n",
      "Iter 1200:loss 0.225882 accuarcy 0.9219\n",
      "Iter 1400:loss 0.304835 accuarcy 0.9062\n",
      "--------epoch 10--------\n",
      "Iter 200:loss 0.334613 accuarcy 0.8906\n",
      "Iter 400:loss 0.325583 accuarcy 0.8906\n",
      "Iter 600:loss 0.182608 accuarcy 0.9219\n",
      "Iter 800:loss 0.339062 accuarcy 0.8906\n",
      "Iter 1000:loss 0.188589 accuarcy 0.9375\n",
      "Iter 1200:loss 0.253856 accuarcy 0.8906\n",
      "Iter 1400:loss 0.216345 accuarcy 0.9375\n",
      "--------epoch 11--------\n",
      "Iter 200:loss 0.369047 accuarcy 0.8438\n",
      "Iter 400:loss 0.408863 accuarcy 0.8750\n",
      "Iter 600:loss 0.212782 accuarcy 0.9531\n",
      "Iter 800:loss 0.221048 accuarcy 0.9375\n",
      "Iter 1000:loss 0.276157 accuarcy 0.8750\n",
      "Iter 1200:loss 0.369842 accuarcy 0.8594\n",
      "Iter 1400:loss 0.263134 accuarcy 0.9531\n",
      "--------epoch 12--------\n",
      "Iter 200:loss 0.240579 accuarcy 0.8906\n",
      "Iter 400:loss 0.204640 accuarcy 0.9531\n",
      "Iter 600:loss 0.201767 accuarcy 0.9219\n",
      "Iter 800:loss 0.210554 accuarcy 0.8906\n",
      "Iter 1000:loss 0.202003 accuarcy 0.9531\n",
      "Iter 1200:loss 0.400546 accuarcy 0.8125\n",
      "Iter 1400:loss 0.379353 accuarcy 0.8750\n",
      "--------epoch 13--------\n",
      "Iter 200:loss 0.331375 accuarcy 0.9062\n",
      "Iter 400:loss 0.256456 accuarcy 0.8906\n",
      "Iter 600:loss 0.295814 accuarcy 0.8906\n",
      "Iter 800:loss 0.504856 accuarcy 0.8594\n",
      "Iter 1000:loss 0.280229 accuarcy 0.9062\n",
      "Iter 1200:loss 0.275168 accuarcy 0.9062\n",
      "Iter 1400:loss 0.416804 accuarcy 0.8125\n",
      "--------epoch 14--------\n",
      "Iter 200:loss 0.180027 accuarcy 0.9688\n",
      "Iter 400:loss 0.148848 accuarcy 0.9531\n",
      "Iter 600:loss 0.213965 accuarcy 0.9219\n",
      "Iter 800:loss 0.202798 accuarcy 0.9375\n",
      "Iter 1000:loss 0.143619 accuarcy 0.9531\n",
      "Iter 1200:loss 0.225255 accuarcy 0.9375\n",
      "Iter 1400:loss 0.383045 accuarcy 0.8438\n",
      "--------epoch 15--------\n",
      "Iter 200:loss 0.220145 accuarcy 0.9062\n",
      "Iter 400:loss 0.403392 accuarcy 0.8281\n",
      "Iter 600:loss 0.164421 accuarcy 0.9531\n",
      "Iter 800:loss 0.278619 accuarcy 0.8906\n",
      "Iter 1000:loss 0.270729 accuarcy 0.8750\n",
      "Iter 1200:loss 0.183482 accuarcy 0.9219\n",
      "Iter 1400:loss 0.381393 accuarcy 0.8438\n",
      "--------epoch 16--------\n",
      "Iter 200:loss 0.225610 accuarcy 0.9219\n",
      "Iter 400:loss 0.185430 accuarcy 0.9531\n",
      "Iter 600:loss 0.223748 accuarcy 0.9531\n",
      "Iter 800:loss 0.471648 accuarcy 0.8281\n",
      "Iter 1000:loss 0.343481 accuarcy 0.8750\n",
      "Iter 1200:loss 0.193611 accuarcy 0.9375\n",
      "Iter 1400:loss 0.327851 accuarcy 0.8906\n",
      "--------epoch 17--------\n",
      "Iter 200:loss 0.111144 accuarcy 0.9531\n",
      "Iter 400:loss 0.224772 accuarcy 0.9375\n",
      "Iter 600:loss 0.192182 accuarcy 0.9062\n",
      "Iter 800:loss 0.204915 accuarcy 0.9531\n",
      "Iter 1000:loss 0.161904 accuarcy 0.9688\n",
      "Iter 1200:loss 0.227242 accuarcy 0.9531\n",
      "Iter 1400:loss 0.149588 accuarcy 0.9531\n",
      "--------epoch 18--------\n",
      "Iter 200:loss 0.217086 accuarcy 0.9375\n",
      "Iter 400:loss 0.164753 accuarcy 0.9375\n",
      "Iter 600:loss 0.124416 accuarcy 0.9844\n",
      "Iter 800:loss 0.164127 accuarcy 0.9688\n",
      "Iter 1000:loss 0.187898 accuarcy 0.9375\n",
      "Iter 1200:loss 0.239327 accuarcy 0.9531\n",
      "Iter 1400:loss 0.164598 accuarcy 0.9375\n",
      "--------epoch 19--------\n",
      "Iter 200:loss 0.175096 accuarcy 0.9375\n",
      "Iter 400:loss 0.126202 accuarcy 0.9375\n",
      "Iter 600:loss 0.215060 accuarcy 0.9531\n",
      "Iter 800:loss 0.183451 accuarcy 0.9531\n",
      "Iter 1000:loss 0.186647 accuarcy 0.9531\n",
      "Iter 1200:loss 0.247756 accuarcy 0.9375\n",
      "Iter 1400:loss 0.159701 accuarcy 0.9531\n",
      "--------epoch 20--------\n",
      "Iter 200:loss 0.104742 accuarcy 0.9688\n",
      "Iter 400:loss 0.248905 accuarcy 0.9375\n",
      "Iter 600:loss 0.167899 accuarcy 0.9219\n",
      "Iter 800:loss 0.118949 accuarcy 0.9531\n",
      "Iter 1000:loss 0.285244 accuarcy 0.9219\n",
      "Iter 1200:loss 0.249150 accuarcy 0.9219\n",
      "Iter 1400:loss 0.199632 accuarcy 0.9062\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(20):\n",
    "    print(f\"--------epoch {epoch+1}--------\")\n",
    "    for (iternum, (X,Y)) in enumerate(train_dataloader,1):\n",
    "    #for (X,Y) in train_dataloader:\n",
    "    #iteration\n",
    "        X,Y=X.cuda(),Y.cuda()\n",
    "    \n",
    "        Y_pred = model(X)\n",
    "        l= loss(Y_pred,Y)\n",
    "    \n",
    "        opt.zero_grad()\n",
    "        l.backward()\n",
    "        opt.step()\n",
    "        #print('hah')\n",
    "        #print(iternum)\n",
    "        #logging\n",
    "        if iternum%200 == 0:\n",
    "            acc =float(torch.sum(torch.argmax(Y_pred, 1) ==Y )) / float(len(Y))\n",
    "            #print(iternum)\n",
    "            print(f\"Iter {iternum}:loss {l:.6f} accuarcy {acc:.4f}\")\n",
    "            #print(acc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for (iternum, (X,Y)) in enumerate(train_dataloader,1):\n",
    "# #for (X,Y) in train_dataloader:\n",
    "#     #iteration\n",
    "#     X,Y=X.cuda(),Y.cuda()\n",
    "    \n",
    "#     Y_pred = model(X)\n",
    "#     l= loss(Y_pred,Y)\n",
    "    \n",
    "#     opt.zero_grad()\n",
    "#     l.backward()\n",
    "#     opt.step()\n",
    "#     #print('hah')\n",
    "#     #print(iternum)\n",
    "#     #logging\n",
    "#     if iternum%200 == 0:\n",
    "#         acc =float(torch.sum(torch.argmax(Y_pred, 1) ==Y )) / float(len(Y))\n",
    "#         #print(iternum)\n",
    "#         print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,\"\\mynet.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"\\mynet.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for test usage - do not modify this\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from more_itertools import chunked\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestData(ImageFolder):\n",
    "    def __getitem__(self, idx):\n",
    "        # drop labels\n",
    "        return super(TestData, self).__getitem__(idx)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datafolder = TestData(data_root[\"test\"], transform=transforms.ToTensor())\n",
    "classes = np.array(test_datafolder.classes)\n",
    "imgs = [x for (x, _) in test_datafolder.imgs]\n",
    "labels = classes[[x for (_, x) in test_datafolder.imgs]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all test images from disk(SSD) into memory\n",
    "# this is expected to take minutes\n",
    "# this may fails due to system kill signal - just try it again later\n",
    "testdata = next(iter(DataLoader(test_datafolder, batch_size=len(test_datafolder))))\n",
    "assert testdata.shape == torch.Size([90000, 3, 32, 32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()\n",
    "testdata = testdata.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, testdata, imgs, labels, batch_size=512):\n",
    "    files_loader = [x for x in chunked(imgs, batch_size)]\n",
    "    test_dataloader = DataLoader(testdata, batch_size=batch_size)\n",
    "    groundtruth_loader = chunked(labels, batch_size)\n",
    "    num_batches = len(files_loader)\n",
    "\n",
    "    columns = [\"file\", \"prediction\", \"ground_truth\"]\n",
    "    data_iter = iter(zip(test_dataloader, files_loader, groundtruth_loader))\n",
    "    df = pd.DataFrame(columns=columns)\n",
    "    for _ in tqdm_notebook(range(num_batches)):\n",
    "        X, filepath, Y = next(data_iter)\n",
    "        with torch.no_grad():\n",
    "            idx = torch.argmax(model(X), 1).cpu()\n",
    "        prediction = classes[idx]\n",
    "\n",
    "        buffer = pd.DataFrame(zip(filepath, prediction, Y), columns=columns)\n",
    "        df = df.append(buffer)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02a39e374446420ba637eb3991f13047",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=176), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>prediction</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>test/airplane/cifar10-test-10.png</td>\n",
       "      <td>dog</td>\n",
       "      <td>airplane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>test/airplane/cifar10-test-1001.png</td>\n",
       "      <td>airplane</td>\n",
       "      <td>airplane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>test/airplane/cifar10-test-1010.png</td>\n",
       "      <td>airplane</td>\n",
       "      <td>airplane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>test/airplane/cifar10-test-1018.png</td>\n",
       "      <td>airplane</td>\n",
       "      <td>airplane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>test/airplane/cifar10-test-1022.png</td>\n",
       "      <td>airplane</td>\n",
       "      <td>airplane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>395</td>\n",
       "      <td>test/truck/n04520170_9909.png</td>\n",
       "      <td>truck</td>\n",
       "      <td>truck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>396</td>\n",
       "      <td>test/truck/n04520170_9936.png</td>\n",
       "      <td>truck</td>\n",
       "      <td>truck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>397</td>\n",
       "      <td>test/truck/n04520170_9942.png</td>\n",
       "      <td>automobile</td>\n",
       "      <td>truck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>398</td>\n",
       "      <td>test/truck/n04520170_9963.png</td>\n",
       "      <td>truck</td>\n",
       "      <td>truck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>399</td>\n",
       "      <td>test/truck/n04520170_9989.png</td>\n",
       "      <td>truck</td>\n",
       "      <td>truck</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    file  prediction ground_truth\n",
       "0      test/airplane/cifar10-test-10.png         dog     airplane\n",
       "1    test/airplane/cifar10-test-1001.png    airplane     airplane\n",
       "2    test/airplane/cifar10-test-1010.png    airplane     airplane\n",
       "3    test/airplane/cifar10-test-1018.png    airplane     airplane\n",
       "4    test/airplane/cifar10-test-1022.png    airplane     airplane\n",
       "..                                   ...         ...          ...\n",
       "395        test/truck/n04520170_9909.png       truck        truck\n",
       "396        test/truck/n04520170_9936.png       truck        truck\n",
       "397        test/truck/n04520170_9942.png  automobile        truck\n",
       "398        test/truck/n04520170_9963.png       truck        truck\n",
       "399        test/truck/n04520170_9989.png       truck        truck\n",
       "\n",
       "[90000 rows x 3 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = evaluate(model, testdata, imgs, labels)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 71.303%\n"
     ]
    }
   ],
   "source": [
    "accu = np.sum(df[\"ground_truth\"] == df[\"prediction\"])/float(len(df)) * 100\n",
    "print(f\"Accuracy {accu:.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在实验中发现，当epoch取足够大时，训练集的准确率能达到100%，但是在测试集的准确率却并没有提高多少。可考虑，增加网络深度等来提高准确率。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在实验刚开始时，是用的torchvision.models.vgg11(pretrained=True)，后来将训练好的保存在mynet.pkl中，后来直接调用。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI-Course",
   "language": "python",
   "name": "ai-course"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
