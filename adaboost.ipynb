{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_iris(ratio=0.8):\n",
    "    features, target = datasets.load_iris(True)\n",
    "    num_samples = len(target)\n",
    "    num_train = math.ceil(num_samples * ratio)\n",
    "    \n",
    "    # 随机打乱数据\n",
    "    idx = np.random.permutation(np.arange(num_samples))\n",
    "    traindata = features[idx[:num_train]], target[idx[:num_train]]\n",
    "    validdata = features[idx[num_train:]], target[idx[num_train:]]\n",
    "    \n",
    "    return traindata, validdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, Y_train), (X_valid, Y_valid) = load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 作业四\n",
    "\n",
    "## 四、AdaBoost算法\n",
    "\n",
    "利用算法8.1对iris数据集进行分类\n",
    "\n",
    "* 利用sklearn提供的`DecisionTreeClassifier`构造单层决策树作为基本分类器\n",
    "* 调整式(8.7)以适用于多分类的情况\n",
    "\n",
    "ETA：0.5-3 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaBoostClassifier:\n",
    "    def __init__(self, n_estimators=50):\n",
    "        self.n_estimators = n_estimators # M\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "          X: array of shape (N, C)\n",
    "          y: array of shape (N, )\n",
    "        \"\"\"\n",
    "        \n",
    "        self.classes_ = np.unique(y)           \n",
    "        self.estimators_ = []\n",
    "        self.estimator_weights_ = np.zeros(self.n_estimators)\n",
    "        self.estimator_errors_ = np.ones(self.n_estimators)\n",
    "        \n",
    "        num_samples = X.shape[0]    # N\n",
    "        sample_weight = np.full((num_samples, ), 1./num_samples)\n",
    "\n",
    "        for iboost in range(self.n_estimators):\n",
    "            sample_weight, estimator, estimator_weight, estimator_error = self._boost(\n",
    "                X, y,\n",
    "                sample_weight)\n",
    "            \n",
    "            self.estimators_.append(estimator)\n",
    "            self.estimator_weights_[iboost] = estimator_weight\n",
    "            self.estimator_errors_[iboost] = estimator_error\n",
    "                            \n",
    "        return self\n",
    "            \n",
    "    def _boost(self, X, y, sample_weight):\n",
    "        estimator = DecisionTreeClassifier(max_depth=1)\n",
    "        estimator.fit(X,y,sample_weight = sample_weight)\n",
    "        \n",
    "        #G_m\n",
    "        G_m = estimator.predict(X) \n",
    "\n",
    "        #e_m\n",
    "        a1 = np.array([sample_weight[i] * (G_m[i] != y[i]) for i in range(X.shape[0])])\n",
    "        estimator_error = np.sum(a1) \n",
    "        \n",
    "        #alpha_m\n",
    "        estimator_weight = 1/2 * np.log((1-estimator_error)/estimator_error)\n",
    "\n",
    "        a2 = np.array([1 if y[i]==G_m[i] else -1 for i in range(y.shape[0])])\n",
    "        \n",
    "        #Z_m\n",
    "        Z_m = 0\n",
    "        for i in range(y.shape[0]):\n",
    "            Z_m += sample_weight[i] * np.exp(-estimator_weight * a2[i] )\n",
    "        \n",
    "        for i in range(y.shape[0]):\n",
    "            sample_weight[i] = sample_weight[i] / Z_m * np.exp(-estimator_weight * a2[i] )\n",
    "                 \n",
    "        \n",
    "        return sample_weight, estimator, estimator_weight, estimator_error\n",
    "    \n",
    "    def predict(self, X):\n",
    "        pred_1 = np.zeros((self.n_estimators, X.shape[0]))\n",
    "        for i in range(len(self.estimators_)):\n",
    "            pred_1[i, :] = self.estimators_[i].predict(X)\n",
    "            \n",
    "            \n",
    "        pred_2 = np.zeros([self.classes_.shape[0], X.shape[0]])\n",
    "\n",
    "        for i in self.classes_:\n",
    "            pred_2[i,:] = np.sum([self.estimator_weights_ * (pred_1[:,j] == i) for j in range(X.shape[0])] , axis = 1)\n",
    "\n",
    "        pred = np.argmax(pred_2,axis = 0)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(Y_real, Y_pred):\n",
    "    return np.sum(Y_real == Y_pred)/len(Y_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model = AdaBoostClassifier()\n",
    "\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "accu = accuracy(model.predict(X_valid), Y_valid)\n",
    "\n",
    "print(f\"Accuracy: {accu:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI-Course",
   "language": "python",
   "name": "ai-course"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
